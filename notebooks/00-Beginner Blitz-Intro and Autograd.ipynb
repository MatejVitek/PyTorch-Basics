{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[7.0715e-39, 1.0653e-38, 9.7347e-39],\n        [4.2246e-39, 1.0286e-38, 1.0653e-38],\n        [1.0194e-38, 8.4490e-39, 1.0469e-38],\n        [9.3674e-39, 9.9184e-39, 8.7245e-39],\n        [9.2755e-39, 8.9082e-39, 9.9184e-39]])\ntensor([[0.1314, 0.1268, 0.2195],\n        [0.4000, 0.8176, 0.2562],\n        [0.6249, 0.3520, 0.9745],\n        [0.6885, 0.4392, 0.3463],\n        [0.7075, 0.7792, 0.6957]])\ntensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])\ntensor([5.5000, 3.0000])\ntensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntensor([[ 1.4499, -1.9741, -0.5165],\n        [ 0.5432, -0.4789, -2.1676],\n        [-1.4314,  0.1402,  0.6525],\n        [-1.0603,  1.0726, -0.5580],\n        [-0.8997,  0.6110,  0.0468]])\ntorch.Size([5, 3])\n"
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)\n",
    "\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[ 1.5519, -1.6431,  0.0872],\n        [ 1.3958, -0.1906, -1.2091],\n        [-0.7778,  1.1099,  1.3758],\n        [-0.1029,  1.6134,  0.1344],\n        [-0.3277,  0.7191,  0.6320]])\ntensor([[ 1.5519, -1.6431,  0.0872],\n        [ 1.3958, -0.1906, -1.2091],\n        [-0.7778,  1.1099,  1.3758],\n        [-0.1029,  1.6134,  0.1344],\n        [-0.3277,  0.7191,  0.6320]])\ntensor([[ 1.5519, -1.6431,  0.0872],\n        [ 1.3958, -0.1906, -1.2091],\n        [-0.7778,  1.1099,  1.3758],\n        [-0.1029,  1.6134,  0.1344],\n        [-0.3277,  0.7191,  0.6320]])\ntensor([[ 1.5519, -1.6431,  0.0872],\n        [ 1.3958, -0.1906, -1.2091],\n        [-0.7778,  1.1099,  1.3758],\n        [-0.1029,  1.6134,  0.1344],\n        [-0.3277,  0.7191,  0.6320]])\ntensor([[ 2.5519, -0.6431,  1.0872],\n        [ 2.3958,  0.8094, -0.2091],\n        [ 0.2222,  2.1099,  2.3758],\n        [ 0.8971,  2.6134,  1.1344],\n        [ 0.6723,  1.7191,  1.6320]])\ntensor([-1.9741, -0.4789,  0.1402,  1.0726,  0.6110])\n"
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "y.add_(x)  # Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "print(y)\n",
    "\n",
    "y += 1\n",
    "print(y)\n",
    "\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([-0.2526])\n-0.2525639832019806\n"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1., 1., 1.])\n[1. 1. 1. 1. 1.]\ntensor([2., 2., 2., 2., 2.])\n[2. 2. 2. 2. 2.]\n[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([0.7474], device='cuda:0')\ntensor([0.7474], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Autograd: Automatic Differentiation #\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 1.],\n        [1., 1.]], requires_grad=True)\ntensor([[3., 3.],\n        [3., 3.]], grad_fn=<AddBackward0>)\n<AddBackward0 object at 0x00000148F4941E80>\ntensor([[27., 27.],\n        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "False\nTrue\n<SumBackward0 object at 0x00000148F4941DC0>\n"
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[4.5000, 4.5000],\n        [4.5000, 4.5000]])\n"
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([-1218.7263,  -190.3329, -1497.5757], grad_fn=<MulBackward0>)\ntensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)\n",
    "\n",
    "v = torch.tensor([.1, 1., .0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\nFalse\nTrue\nFalse\ntensor(True)\n"
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)\n",
    "\n",
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  }
 ]
}